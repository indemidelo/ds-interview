{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(os.listdir(os.curdir))\n",
    "x_train = pd.read_csv('train.csv')\n",
    "x_test = pd.read_csv('test.csv')\n",
    "y_test = pd.read_csv('gender_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.info()\n",
    "x_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data exploration with some histogram: is there a correlation between the Survived col and the others?\n",
    "\n",
    "x_train.hist('Survived')\n",
    "# there are more dead than survived passengers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.hist('Survived', by='Pclass', layout=[1, 3], figsize=[10, 3])\n",
    "# by = group by the column; layout = how to dispose the plots; figsize= resize the plots (usually to fit them better on one line or column)\n",
    "# The higher the class, the higher the probability of survive\n",
    "# The second class passengers are almost evenly distributed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.hist('Survived', by='Sex', layout=[1, 2], figsize=[10, 4])\n",
    "# Being a woman would have enhanced your chances to survive the disaster"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.hist('Survived', by='Embarked', layout=[1, 3], figsize=[10, 3])\n",
    "# If you embarked in the port of Cherbourg you had higher chances to live.\n",
    "# Maybe the port is correlated with the passenger's class?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.hist('Pclass', by='Embarked', layout=[1, 3], figsize=[10, 3],\n",
    "             sharey=True)\n",
    "# a correlation could be spotted, but should be further investigated.\n",
    "# we can assert that almost half of the passengers embarked in C had a first\n",
    "# class ticket, even if the majority of them embarked in S."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histogram of Age grouped by Survived and Sex, bins=step to divide the Age variables into\n",
    "x_train.hist('Age', bins=10, by=['Survived', 'Sex'])\n",
    "x_train.hist('Age', bins=10, by=['Survived', 'Sex'],\n",
    "             sharex=True, sharey=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Embarked vs sex\n",
    "# get_dummies does one-hot-encoding. drop_first avoid the creation of a correlated column\n",
    "is_male = pd.get_dummies(x_train['Sex'], drop_first=True)\n",
    "x_train['is_male'] = is_male\n",
    "x_train.hist('is_male', by='Embarked', layout=[1, 3], figsize=[10, 3],\n",
    "             sharey=True)\n",
    "\n",
    "x_train.hist('is_male', by=['Embarked', 'Pclass'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "x_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we are going to impute all those missing data points with the median Age.\n",
    "# But since we have the Title of every passenger, we infer their Age 'Title' group wise  \n",
    "# expand serves to return always a DataFrame\n",
    "x_train['title'] = x_train['Name'].str.lower().str.extract('([a-z]*\\.)', expand=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Some examples\n",
    "missing_age = dict()\n",
    "missing_age['dr.'] = x_train[((x_train['Age'].isnull()==True) & (x_train['title']=='dr.'))].index.tolist()\n",
    "missing_age['mister.'] = x_train[((x_train['Age'].isnull()==True) & (x_train['title']=='mister.'))].index.tolist()\n",
    "missing_age['miss.'] = x_train[((x_train['Age'].isnull()==True) & (x_train['title']=='miss.'))].index.tolist()\n",
    "missing_age['mr.'] = x_train[((x_train['Age'].isnull()==True) & (x_train['title']=='mr.'))].index.tolist()\n",
    "missing_age['mrs.'] = x_train[((x_train['Age'].isnull()==True) & (x_train['title']=='mrs.'))].index.tolist()\n",
    "\n",
    "for k, v in missing_age.items():\n",
    "    if v:\n",
    "        missing_age[k] = v[0]\n",
    "    else:\n",
    "        missing_age[k] = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_missing_age_pid = [False for _ in range(x_train.shape[0])]\n",
    "for j in missing_age.values(): \n",
    "    if j: \n",
    "        is_missing_age_pid[j] = True\n",
    "x_train[is_missing_age_pid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remember that a sentence must be included in brackets to be considered valid by pandas.\n",
    "# i.e.  df[A & B] KO\n",
    "#       df[(A) & (B)] OK\n",
    "# df[<condition>] works like the `which` function in R. It allows to select only the data points \n",
    "# that respect the condition in the square brackets\n",
    "avg_dr = x_train[((x_train['title'] == 'dr.') & (x_train['Age'].isnull() == False))]['Age'].median()\n",
    "avg_master = x_train[((x_train['title'] == 'master.') & (x_train['Age'].isnull() == False))]['Age'].median()\n",
    "avg_miss = x_train[((x_train['title'] == 'miss.') & (x_train['Age'].isnull() == False))]['Age'].median()\n",
    "avg_mr = x_train[((x_train['title'] == 'mr.') & (x_train['Age'].isnull() == False))]['Age'].median()\n",
    "avg_mrs = x_train[((x_train['title'] == 'mrs.') & (x_train['Age'].isnull() == False))]['Age'].median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now to replace the missing values. We can do it with a for loop or with a single command.\n",
    "# Let's use the df.loc function. \n",
    "# df[condition] export the data points only for visualization purposes; to modify them we use df.loc\n",
    "# The syntax is df.loc[<row condition>, <column condition>]\n",
    "# the column condition can be just the name of the column as a string\n",
    "# the .tolist() method transform a dataframe into a list. maybe unnecessary\n",
    "x_train.loc[((x_train['title'] == 'dr.') & (x_train['Age'].isnull()==True)).tolist(), 'Age'] = avg_dr\n",
    "x_train.loc[((x_train['title'] == 'master.') & (x_train['Age'].isnull()==True)).tolist(), 'Age'] = avg_master\n",
    "x_train.loc[((x_train['title'] == 'miss.') & (x_train['Age'].isnull()==True)).tolist(), 'Age'] = avg_miss\n",
    "x_train.loc[((x_train['title'] == 'mr.') & (x_train['Age'].isnull()==True)).tolist(), 'Age'] = avg_mr\n",
    "x_train.loc[((x_train['title'] == 'mrs.') & (x_train['Age'].isnull()==True)).tolist(), 'Age'] = avg_mrs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apparently pandas wants a list of booleans of the same dimension of the df to select specific rows\n",
    "x_train.loc[is_missing_age_pid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hypothesis Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Student's t-test\n",
    "Statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis.\n",
    "(see https://en.wikipedia.org/wiki/Student%27s_t-test for details)\n",
    "\n",
    "Two of the most common uses are:\n",
    "\n",
    "1. A *one-sample* location test of whether **the mean has a value specified** in the null hp\n",
    "2. A *two-samples* location test of the null hp such that **the means of two populations are equal**. This works if the variances of the population are also assumed equal. If this assumption is dropped, the Welch t-test can be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We will measure whether the average age of the survived differs from the age of the dead passengers\n",
    "# First we need to compute the sample variance of the two population (survived vs dead):\n",
    "x_surv = x_train.loc[x_train['Survived'].tolist()]\n",
    "x_dead = x_train.loc[(1-x_train['Survived']).tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_surv = x_train[x_train['Survived'] == 1]\n",
    "x_surv.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_dead = x_train[x_train['Survived'] == 0]\n",
    "x_dead.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{'var_surv': x_surv['Age'].var(), 'var_dead': x_dead['Age'].var()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The two population do not have the same variance, \n",
    "# but we will try both the tests (same sample variance and different sample variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standard independent 2-sample test: the population variances are assumed equal\n",
    "# H0: mu_surv = mu_dead vs H1: mu_surv <> mu_dead\n",
    "statistic, pvalue = stats.ttest_ind(x_surv['Age'].array, x_dead['Age'].array)\n",
    "pvalue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The *pvalue* is **the probability of obtaining results as extreme as the observed result of a statistical hypothesis test, assuming the null hypothesis is true**.\n",
    "The statistical hp test is built using the population (i.e. its population average and variance).\n",
    "\n",
    "For example the statistical hypothesis Student's t-test is: $$Y_{0} = \\frac{\\bar{X}-\\mu_{0}}{s/\\sqrt n}$$ where:\n",
    "\n",
    "- $\\bar{X}$ is the population mean\n",
    "- $\\mu_{0}$ is the null hypothesis value to be tested\n",
    "- $s$ is the population standard deviation\n",
    "- $n$ is the number of samples\n",
    "\n",
    "The pvalue is $$P(Y \\geq Y_{0}|H_{0})$$\n",
    "\n",
    "Seeing everything from a stat hp test perspective, we can reformulate $H_{0}$ as the hypothesis that $Y_{0}$ or a more extreme value can be drawn from $Y$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BUT\n",
    "\n",
    "$$P(observation|hypothesis) \\neq P(hypothesis|observation)$$\n",
    "\n",
    "thus using the pvalue as a score is committing a logical error: the *tranposed condition fallacy*.\n",
    "It is not true to assert that if the probability of an observation under a hp is low, than the probability that given the observation the hp is true is low. The two numbers can be very different.\n",
    "\n",
    "In our case, we are estimating the probability that the $H_0: \\mu_{surv}=\\mu_{dead}$ is valid given the data with the probability that, given the null hp, we should draw a result as extreme as the one from the statistical hp test.\n",
    "Since this value is far away from the center of the distribution, the probability of drawing it (pvalue) is low.\n",
    "\n",
    "Thus there is statistical evidence to reject the null hypothesis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Welch 2-sample test: the population variances are different\n",
    "# equal_var = False\n",
    "# H0: mu_surv = mu_dead vs H1: mu_surv <> mu_dead\n",
    "statistic, pvalue = stats.ttest_ind(x_surv['Age'].array, x_dead['Age'].array, equal_var=False)\n",
    "pvalue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Still pretty low.\n",
    "# If we had a known variance and a normal distribution, we could have used the z-test.\n",
    "# If the variance is unknown, the Student's t-test shall be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chi-squared test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chi-square test tests the null hypothesis that **the categorical data has the given frequencies**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Table of frequencies\n",
    "crosstab = pd.crosstab(x_train['Survived'], [x_train['Sex'], x_train['Pclass']])\n",
    "crosstab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's test that the proportion of survived males is independent from the passenger's class\n",
    "crosstab = pd.crosstab(x_train['Survived'][x_train['Sex']=='male'], [x_train['Pclass'][x_train['Sex']=='male']])\n",
    "crosstab_males = crosstab.to_numpy()[1]\n",
    "crosstab_males"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# expected frequency\n",
    "f_exp = [int(sum(crosstab_males)/3) for j in crosstab_males]\n",
    "f_exp[0] = int(f_exp[0]) + 1\n",
    "f_exp = np.array(f_exp).astype(np.int64)\n",
    "f_exp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "chisquare([45, 17, 47], f_exp=f_exp)\n",
    "# chisquare(crosstab_males, f_exp=f_exp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Power_divergence is probably a module bug\n",
    "# H0 rejected. Let's try another one based on crosstab: females survived vs males survived\n",
    "crosstab_surv = pd.crosstab(x_train['Sex'][x_train['Survived']==1], [x_train['Pclass'][x_train['Survived']==1]])\n",
    "crosstab_surv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crosstab_surv.astype(np.int64)\n",
    "chisquare(crosstab_surv.to_numpy()[0,], crosstab_surv.to_numpy()[1,])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Even lower! No statistical evidence to accept H0. Qui esce power divergence perchè sta provando un altro test, in cui\n",
    "# la somma delle frequenze è diversa tra le popolazioni. Se fossero identiche mi farebbe correttamente chisquare"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Two-samples *t*-test for Equal Means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The two-sample t-test is used to determine if two population means are equal. A common application is to test if a new process or treatment is superior to a current process or treatment. The two population have different distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are several variations on this test.\n",
    "\n",
    "1. The data may either be paired or not paired. By paired, we mean that there is a one-to-one correspondence between the values in the two samples. That is, if $X_1,X_2,\\dots,X_n$ and $Y_1,Y_2,\\dots,Y_n$ are the two samples, then $X_i$ corresponds to $Y_i$. For paired samples, the difference $X_i - Y_i$ is usually calculated. For unpaired samples, the sample sizes for the two samples may or may not be equal. The formulas for paired data are somewhat simpler than the formulas for unpaired data.\n",
    "2. The variances of the two samples may be assumed to be equal or unequal. Equal variances yields somewhat simpler formulas, although with computers this is no longer a significant issue.\n",
    "3. In some applications, you may want to adopt a new process or treatment only if it exceeds the current treatment by some threshold. In this case, we can state the null hypothesis in the form that the difference between the two populations means is equal to some constant $\\mu_1−\\mu_2=d_0$ where the constant is the desired threshold."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **two-sample t-test** for unpaired data is defined as:\n",
    "$$H_0:\t\\mu_1=\\mu_2$$\n",
    "$$H_a:\t\\mu_1\\neq\\mu_2$$\n",
    "\n",
    "\n",
    "Test Statistic:\t$T=\\frac{Y_1−Y_2}{\\sqrt{s^2_1/N_1+s^2_2/N_2}}$\n",
    "\n",
    "where $N_1$ and $N_2$ are the sample sizes, $Y_1$ and $Y_2$ are the sample means, and $s^2_1$ and $s^2_2$ are the sample variances.\n",
    "\n",
    "If equal variances are assumed, then the formula reduces to: $T=\\frac{Y_1−Y_2}{s_{p}\\sqrt{1/N_1+1/N_2}}$\n",
    "\n",
    "where $s^2_p=\\frac{(N_1−1)s^2_1+(N_2−1)s^2_2}{N_1+N_2−2}$\n",
    "\n",
    "Significance Level: $\\alpha$.\n",
    "\n",
    "Critical Region: Reject the null hypothesis that the two means are equal if $|T| > t_{1-\\alpha/2$,ν}$\n",
    "\n",
    "where $t_{1-α/2,ν}$ is the **critical value** of the **t distribution** with ν degrees of freedom where\n",
    "$$ν=\\frac{(s^2_1/N_1+s^2_2/N_2)^2}{(s^2_1/N_1)^2/(N_1−1)+(s^2_2/N_2)^2/(N_2−1)}$$\n",
    "\n",
    "If equal variances are assumed, then $$ν = N_1 + N_2 - 2$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confidence Intervals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--Theory for confidence intervals--\n",
    "\n",
    "Before diving in, keep in mind that the *mean of the population* (the thing we what to estimate) is a constant, there is no randomness about the number.\n",
    "\n",
    "The confidence interval is an estimator we use to estimate the value of population parameters. The interval will create a range that might contain the values. When we create the interval, we use a sample mean. Recall the central limit theorem, if we sample many times, the sample mean will be normally distributed.\n",
    "\n",
    "This proposes a range of plausible values for an unknown parameter (for example, the mean). The interval has an associated confidence level that the true parameter is in the proposed range. Given observations $x_{1},\\ldots ,x_{n}$ and a confidence level $\\gamma$ , a valid confidence interval has a $\\gamma$  probability of containing the true underlying parameter. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the Student's t-distribution the interval whose endpoints are\n",
    "$$\\overline {X}_{n}\\pm A{\\frac {S_{n}}{\\sqrt {n}}}$$\n",
    "is a 90% confidence interval for $\\mu$, where $A$ is the \"95th percentile\" of this probability distribution, or $A=t_{(0.05,n-1)}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Three ways to get them with the `scipy` module:\n",
    "1. `st.t.interval` correct also for small n\n",
    "2. `statsmodel.stats.api.DescrStatsW` correct also for small n\n",
    "3. `st.norm.interval` correct only in case of a normal distributed sample or n>30 (for large sample size the sample mean is normally distributed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use **Confidence Intervals** to estimate parameters of the model (the fitted response $y$ included).\n",
    "\n",
    "To estimate *new data points*, aka *new values of the response variable*, we use the **Prediction Intervals**.\n",
    "\n",
    "The new observation are independent of the observations used to obtain the model.\n",
    "\n",
    "If a confidence interval needs to be obtained on $\\hat{y}_{new}$, then this interval should include both the error from the fitted model and the error associated with future observations. This is because $\\hat{y}_{new}$ represents the estimate for a value of $Y$ that was not used to obtain the regression model. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction Intervals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A prediction interval is a range that is likely to contain the response value of a single new observation given specified settings of the predictors in your model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANOVA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "males = x_train[x_train['Sex']=='male']['Age']\n",
    "females = x_train[x_train['Sex']=='female']['Age']\n",
    "stats.f_oneway(males, females)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pvalue is low: there is stastical significance to reject the null hypothesis that the males and females on the Titanic had the same average age.\n",
    "\n",
    "Let's do the same (one-way anova) with the survival variable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surv = x_train[x_train['Survived']==1]['Age']\n",
    "dead = x_train[x_train['Survived']==0]['Age']\n",
    "stats.f_oneway(surv, dead)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pvalue here is bigger but not big enough to accept the null hypothesis.\n",
    "\n",
    "From the graphs above we should find two populations with the same mean..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since we are lazy, we create two population with a very similar mean and test them\n",
    "np.random.seed(123)\n",
    "x1 = np.random.normal(loc=0, scale=1, size=1000)\n",
    "x2 = np.random.normal(loc=0.0001, scale=1, size=500)\n",
    "stats.f_oneway(x1, x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally! The two samples share the same mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I want to try to draw a ROC Curve, so I need a logistic regression\n",
    "x_lr = x_train.loc[:,['Fare']]\n",
    "y_lr = x_train.Survived"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_lr, y_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_lr)[:,1] # probability of Survival\n",
    "y_pred = model.predict(x_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.predict_proba(x_lr)[0], y_pred[0], y_lr[0]\n",
    "model.predict_proba(x_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_lr, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_lr, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_lr, y_hat)\n",
    "roc_auc = roc_auc_score(y_lr, y_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the ROC Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References:\n",
    "1. pandas https://www.kaggle.com/inturiyam/exploring-titanic-data-using-pandas-dataframes/data\n",
    "2. confidence intervals https://towardsdatascience.com/illustration-with-python-confidence-interval-ee4736cc3dc2\n",
    "3. chi-squared and why n-1 dof https://it.wikipedia.org/wiki/Test_chi_quadrato\n",
    "4. ROC Curve in Python https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}